{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and the test weekly fpl scrape\n",
    "season=\"2019-20\"\n",
    "gw=9\n",
    "model_type=\"nn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import regularizers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(os.getcwd(), \"..\", \"..\", \"data\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = np.random.seed(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"x-train.csv\");\n",
    "X_test = pd.read_csv(\"x-test.csv\");\n",
    "X_val = pd.read_csv(\"x-val.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(\"y-train.csv\");\n",
    "y_test = pd.read_csv(\"y-test.csv\");\n",
    "y_val = pd.read_csv(\"y-val.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape:  (43116, 68)\n",
      "y train shape:  (43116, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X train shape: \", X_train.shape)\n",
    "print(\"y train shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X test shape:  (14372, 68)\n",
      "y test shape:  (14372, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X test shape: \", X_test.shape)\n",
    "print(\"y test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X val shape:  (14372, 68)\n",
      "y val shape:  (14372, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X val shape: \", X_val.shape)\n",
    "print(\"y val shape: \", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled = scaler.fit_transform(X_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(dim, dropout=0.1, l2_reg=0.01, regress=False):\n",
    "    # define our MLP network\n",
    "    model = Sequential();\n",
    "    \n",
    "    model.add(Dense(8, input_dim=dim, kernel_regularizer=regularizers.l2(l2_reg), activation=\"elu\"));\n",
    "    model.add(Dropout(dropout));\n",
    "    model.add(Dense(7, kernel_regularizer=regularizers.l2(l2_reg), activation=\"elu\"));\n",
    "    model.add(Dropout(dropout));\n",
    "    model.add(Dense(6, kernel_regularizer=regularizers.l2(l2_reg), activation=\"elu\"));\n",
    "    model.add(Dropout(dropout));\n",
    "    model.add(Dense(5, kernel_regularizer=regularizers.l2(l2_reg), activation=\"elu\"));\n",
    "    model.add(Dropout(dropout));\n",
    "    model.add(Dense(4, kernel_regularizer=regularizers.l2(l2_reg), activation=\"elu\"));\n",
    "    model.add(Dropout(dropout));\n",
    "    model.add(Dense(3, kernel_regularizer=regularizers.l2(l2_reg), activation=\"elu\"));\n",
    "    model.add(Dropout(dropout));\n",
    "    model.add(Dense(2, kernel_regularizer=regularizers.l2(l2_reg), activation=\"elu\"));\n",
    "    model.add(Dropout(dropout));\n",
    " \n",
    "    # check to see if the regression node should be added\n",
    "    if regress:\n",
    "        model.add(Dense(1, kernel_regularizer=regularizers.l2(l2_reg), activation=\"linear\"));\n",
    " \n",
    "    # return our model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1017 10:31:25.327574 4606776768 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1017 10:31:25.355540 4606776768 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1017 10:31:25.363941 4606776768 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1017 10:31:25.386219 4606776768 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1017 10:31:25.393109 4606776768 deprecation.py:506] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1017 10:31:25.614089 4606776768 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = create_mlp(X_train.shape[1], dropout=0.07, l2_reg=0.07, regress=True)\n",
    "opt = keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=opt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=10,\n",
    "                              verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1017 10:31:26.105390 4606776768 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43116 samples, validate on 14372 samples\n",
      "Epoch 1/500\n",
      "43116/43116 [==============================] - 3s 68us/step - loss: 13.2213 - val_loss: 8.3085\n",
      "Epoch 2/500\n",
      "43116/43116 [==============================] - 2s 51us/step - loss: 7.8043 - val_loss: 7.1906\n",
      "Epoch 3/500\n",
      "43116/43116 [==============================] - 2s 50us/step - loss: 6.8895 - val_loss: 6.5337\n",
      "Epoch 4/500\n",
      "43116/43116 [==============================] - 2s 53us/step - loss: 6.3250 - val_loss: 6.0362\n",
      "Epoch 5/500\n",
      "43116/43116 [==============================] - 2s 48us/step - loss: 5.9720 - val_loss: 5.6885\n",
      "Epoch 6/500\n",
      "43116/43116 [==============================] - 2s 47us/step - loss: 5.7083 - val_loss: 5.4364\n",
      "Epoch 7/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 5.4832 - val_loss: 5.2209\n",
      "Epoch 8/500\n",
      "43116/43116 [==============================] - 2s 47us/step - loss: 5.2855 - val_loss: 5.0483\n",
      "Epoch 9/500\n",
      "43116/43116 [==============================] - 2s 44us/step - loss: 5.1178 - val_loss: 4.8986\n",
      "Epoch 10/500\n",
      "43116/43116 [==============================] - 2s 43us/step - loss: 4.9438 - val_loss: 4.7781\n",
      "Epoch 11/500\n",
      "43116/43116 [==============================] - 2s 43us/step - loss: 4.7751 - val_loss: 4.6852\n",
      "Epoch 12/500\n",
      "43116/43116 [==============================] - 2s 43us/step - loss: 4.6816 - val_loss: 4.6109\n",
      "Epoch 13/500\n",
      "43116/43116 [==============================] - 2s 46us/step - loss: 4.5929 - val_loss: 4.5573\n",
      "Epoch 14/500\n",
      "43116/43116 [==============================] - 2s 42us/step - loss: 4.5511 - val_loss: 4.5111\n",
      "Epoch 15/500\n",
      "43116/43116 [==============================] - 2s 43us/step - loss: 4.4943 - val_loss: 4.4747\n",
      "Epoch 16/500\n",
      "43116/43116 [==============================] - 2s 42us/step - loss: 4.4653 - val_loss: 4.4433\n",
      "Epoch 17/500\n",
      "43116/43116 [==============================] - 2s 44us/step - loss: 4.4363 - val_loss: 4.4203\n",
      "Epoch 18/500\n",
      "43116/43116 [==============================] - 2s 43us/step - loss: 4.4121 - val_loss: 4.4017\n",
      "Epoch 19/500\n",
      "43116/43116 [==============================] - 2s 44us/step - loss: 4.3650 - val_loss: 4.3832\n",
      "Epoch 20/500\n",
      "43116/43116 [==============================] - 2s 44us/step - loss: 4.3541 - val_loss: 4.3751\n",
      "Epoch 21/500\n",
      "43116/43116 [==============================] - 2s 44us/step - loss: 4.3585 - val_loss: 4.3570\n",
      "Epoch 22/500\n",
      "43116/43116 [==============================] - 2s 43us/step - loss: 4.3361 - val_loss: 4.3472\n",
      "Epoch 23/500\n",
      "43116/43116 [==============================] - 2s 46us/step - loss: 4.3270 - val_loss: 4.3388\n",
      "Epoch 24/500\n",
      "43116/43116 [==============================] - 2s 47us/step - loss: 4.3027 - val_loss: 4.3259\n",
      "Epoch 25/500\n",
      "43116/43116 [==============================] - 2s 44us/step - loss: 4.3099 - val_loss: 4.3192\n",
      "Epoch 26/500\n",
      "43116/43116 [==============================] - 2s 44us/step - loss: 4.2984 - val_loss: 4.3149\n",
      "Epoch 27/500\n",
      "43116/43116 [==============================] - 2s 46us/step - loss: 4.2886 - val_loss: 4.3076\n",
      "Epoch 28/500\n",
      "43116/43116 [==============================] - 2s 48us/step - loss: 4.2964 - val_loss: 4.3025\n",
      "Epoch 29/500\n",
      "43116/43116 [==============================] - 2s 48us/step - loss: 4.2892 - val_loss: 4.2988\n",
      "Epoch 30/500\n",
      "43116/43116 [==============================] - 2s 47us/step - loss: 4.2609 - val_loss: 4.2952\n",
      "Epoch 31/500\n",
      "43116/43116 [==============================] - 2s 48us/step - loss: 4.2666 - val_loss: 4.2909\n",
      "Epoch 32/500\n",
      "43116/43116 [==============================] - 2s 51us/step - loss: 4.2762 - val_loss: 4.2897\n",
      "Epoch 33/500\n",
      "43116/43116 [==============================] - 2s 53us/step - loss: 4.2684 - val_loss: 4.2896\n",
      "Epoch 34/500\n",
      "43116/43116 [==============================] - 2s 43us/step - loss: 4.2659 - val_loss: 4.2866\n",
      "Epoch 35/500\n",
      "43116/43116 [==============================] - 2s 44us/step - loss: 4.2680 - val_loss: 4.2841\n",
      "Epoch 36/500\n",
      "43116/43116 [==============================] - 2s 46us/step - loss: 4.2570 - val_loss: 4.2835\n",
      "Epoch 37/500\n",
      "43116/43116 [==============================] - 2s 43us/step - loss: 4.2548 - val_loss: 4.2806\n",
      "Epoch 38/500\n",
      "43116/43116 [==============================] - 2s 46us/step - loss: 4.2558 - val_loss: 4.2806\n",
      "Epoch 39/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2648 - val_loss: 4.2814\n",
      "Epoch 40/500\n",
      "43116/43116 [==============================] - 2s 46us/step - loss: 4.2566 - val_loss: 4.2774\n",
      "Epoch 41/500\n",
      "43116/43116 [==============================] - 2s 50us/step - loss: 4.2547 - val_loss: 4.2765\n",
      "Epoch 42/500\n",
      "43116/43116 [==============================] - 2s 47us/step - loss: 4.2647 - val_loss: 4.2750\n",
      "Epoch 43/500\n",
      "43116/43116 [==============================] - 2s 44us/step - loss: 4.2627 - val_loss: 4.2751\n",
      "Epoch 44/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2546 - val_loss: 4.2744\n",
      "Epoch 45/500\n",
      "43116/43116 [==============================] - 2s 44us/step - loss: 4.2515 - val_loss: 4.2721\n",
      "Epoch 46/500\n",
      "43116/43116 [==============================] - 2s 46us/step - loss: 4.2462 - val_loss: 4.2727\n",
      "Epoch 47/500\n",
      "43116/43116 [==============================] - 2s 43us/step - loss: 4.2491 - val_loss: 4.2690\n",
      "Epoch 48/500\n",
      "43116/43116 [==============================] - 2s 43us/step - loss: 4.2353 - val_loss: 4.2696\n",
      "Epoch 49/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2488 - val_loss: 4.2655\n",
      "Epoch 50/500\n",
      "43116/43116 [==============================] - 2s 44us/step - loss: 4.2482 - val_loss: 4.2656\n",
      "Epoch 51/500\n",
      "43116/43116 [==============================] - 2s 46us/step - loss: 4.2557 - val_loss: 4.2658\n",
      "Epoch 52/500\n",
      "43116/43116 [==============================] - 2s 47us/step - loss: 4.2492 - val_loss: 4.2671\n",
      "Epoch 53/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2518 - val_loss: 4.2658\n",
      "Epoch 54/500\n",
      "43116/43116 [==============================] - 2s 51us/step - loss: 4.2410 - val_loss: 4.2648\n",
      "Epoch 55/500\n",
      "43116/43116 [==============================] - 2s 49us/step - loss: 4.2446 - val_loss: 4.2674\n",
      "Epoch 56/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2411 - val_loss: 4.2625\n",
      "Epoch 57/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2252 - val_loss: 4.2599\n",
      "Epoch 58/500\n",
      "43116/43116 [==============================] - 2s 50us/step - loss: 4.2397 - val_loss: 4.2641\n",
      "Epoch 59/500\n",
      "43116/43116 [==============================] - 2s 49us/step - loss: 4.2481 - val_loss: 4.2611\n",
      "Epoch 60/500\n",
      "43116/43116 [==============================] - 2s 47us/step - loss: 4.2297 - val_loss: 4.2598\n",
      "Epoch 61/500\n",
      "43116/43116 [==============================] - 2s 48us/step - loss: 4.2423 - val_loss: 4.2624\n",
      "Epoch 62/500\n",
      "43116/43116 [==============================] - 2s 46us/step - loss: 4.2339 - val_loss: 4.2580\n",
      "Epoch 63/500\n",
      "43116/43116 [==============================] - 2s 46us/step - loss: 4.2447 - val_loss: 4.2591\n",
      "Epoch 64/500\n",
      "43116/43116 [==============================] - 2s 48us/step - loss: 4.2419 - val_loss: 4.2574\n",
      "Epoch 65/500\n",
      "43116/43116 [==============================] - 2s 46us/step - loss: 4.2394 - val_loss: 4.2569\n",
      "Epoch 66/500\n",
      "43116/43116 [==============================] - 2s 46us/step - loss: 4.2399 - val_loss: 4.2555\n",
      "Epoch 67/500\n",
      "43116/43116 [==============================] - 2s 46us/step - loss: 4.2318 - val_loss: 4.2548\n",
      "Epoch 68/500\n",
      "43116/43116 [==============================] - 2s 48us/step - loss: 4.2343 - val_loss: 4.2551\n",
      "Epoch 69/500\n",
      "43116/43116 [==============================] - 2s 46us/step - loss: 4.2375 - val_loss: 4.2550\n",
      "Epoch 70/500\n",
      "43116/43116 [==============================] - 2s 49us/step - loss: 4.2334 - val_loss: 4.2524\n",
      "Epoch 71/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2332 - val_loss: 4.2545\n",
      "Epoch 72/500\n",
      "43116/43116 [==============================] - 2s 49us/step - loss: 4.2330 - val_loss: 4.2526\n",
      "Epoch 73/500\n",
      "43116/43116 [==============================] - 2s 47us/step - loss: 4.2241 - val_loss: 4.2499\n",
      "Epoch 74/500\n",
      "43116/43116 [==============================] - 2s 48us/step - loss: 4.2260 - val_loss: 4.2503\n",
      "Epoch 75/500\n",
      "43116/43116 [==============================] - 2s 49us/step - loss: 4.2362 - val_loss: 4.2527\n",
      "Epoch 76/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2337 - val_loss: 4.2517\n",
      "Epoch 77/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2332 - val_loss: 4.2528\n",
      "Epoch 78/500\n",
      "43116/43116 [==============================] - 2s 46us/step - loss: 4.2406 - val_loss: 4.2511\n",
      "Epoch 79/500\n",
      "43116/43116 [==============================] - 2s 47us/step - loss: 4.2274 - val_loss: 4.2515\n",
      "Epoch 80/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2293 - val_loss: 4.2498\n",
      "Epoch 81/500\n",
      "43116/43116 [==============================] - 2s 48us/step - loss: 4.2291 - val_loss: 4.2498\n",
      "Epoch 82/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2385 - val_loss: 4.2500\n",
      "Epoch 83/500\n",
      "43116/43116 [==============================] - 2s 44us/step - loss: 4.2413 - val_loss: 4.2487\n",
      "Epoch 84/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2255 - val_loss: 4.2522\n",
      "Epoch 85/500\n",
      "43116/43116 [==============================] - 2s 48us/step - loss: 4.2319 - val_loss: 4.2505\n",
      "Epoch 86/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2299 - val_loss: 4.2495\n",
      "Epoch 87/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2204 - val_loss: 4.2467\n",
      "Epoch 88/500\n",
      "43116/43116 [==============================] - 2s 44us/step - loss: 4.2306 - val_loss: 4.2477\n",
      "Epoch 89/500\n",
      "43116/43116 [==============================] - 2s 44us/step - loss: 4.2256 - val_loss: 4.2496\n",
      "Epoch 90/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2225 - val_loss: 4.2473\n",
      "Epoch 91/500\n",
      "43116/43116 [==============================] - 2s 47us/step - loss: 4.2305 - val_loss: 4.2485\n",
      "Epoch 92/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2244 - val_loss: 4.2467\n",
      "Epoch 93/500\n",
      "43116/43116 [==============================] - 2s 43us/step - loss: 4.2355 - val_loss: 4.2458\n",
      "Epoch 94/500\n",
      "43116/43116 [==============================] - 2s 47us/step - loss: 4.2277 - val_loss: 4.2450\n",
      "Epoch 95/500\n",
      "43116/43116 [==============================] - 2s 43us/step - loss: 4.2250 - val_loss: 4.2454\n",
      "Epoch 96/500\n",
      "43116/43116 [==============================] - 2s 44us/step - loss: 4.2339 - val_loss: 4.2465\n",
      "Epoch 97/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2245 - val_loss: 4.2447\n",
      "Epoch 98/500\n",
      "43116/43116 [==============================] - 2s 43us/step - loss: 4.2338 - val_loss: 4.2441\n",
      "Epoch 99/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2387 - val_loss: 4.2458\n",
      "Epoch 100/500\n",
      "43116/43116 [==============================] - 2s 43us/step - loss: 4.2338 - val_loss: 4.2452\n",
      "Epoch 101/500\n",
      "43116/43116 [==============================] - 2s 43us/step - loss: 4.2191 - val_loss: 4.2458\n",
      "Epoch 102/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2329 - val_loss: 4.2426\n",
      "Epoch 103/500\n",
      "43116/43116 [==============================] - 2s 48us/step - loss: 4.2208 - val_loss: 4.2454\n",
      "Epoch 104/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2344 - val_loss: 4.2442\n",
      "Epoch 105/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2212 - val_loss: 4.2501\n",
      "Epoch 106/500\n",
      "43116/43116 [==============================] - 2s 43us/step - loss: 4.2323 - val_loss: 4.2438\n",
      "Epoch 107/500\n",
      "43116/43116 [==============================] - 2s 49us/step - loss: 4.2127 - val_loss: 4.2415\n",
      "Epoch 108/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2330 - val_loss: 4.2465\n",
      "Epoch 109/500\n",
      "43116/43116 [==============================] - 2s 48us/step - loss: 4.2294 - val_loss: 4.2430\n",
      "Epoch 110/500\n",
      "43116/43116 [==============================] - 2s 50us/step - loss: 4.2184 - val_loss: 4.2430\n",
      "Epoch 111/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2278 - val_loss: 4.2422\n",
      "Epoch 112/500\n",
      "43116/43116 [==============================] - 2s 47us/step - loss: 4.2280 - val_loss: 4.2419\n",
      "Epoch 113/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2337 - val_loss: 4.2411\n",
      "Epoch 114/500\n",
      "43116/43116 [==============================] - 2s 44us/step - loss: 4.2202 - val_loss: 4.2443\n",
      "Epoch 115/500\n",
      "43116/43116 [==============================] - 2s 46us/step - loss: 4.2236 - val_loss: 4.2416\n",
      "Epoch 116/500\n",
      "43116/43116 [==============================] - 2s 46us/step - loss: 4.2204 - val_loss: 4.2409\n",
      "Epoch 117/500\n",
      "43116/43116 [==============================] - 2s 46us/step - loss: 4.2225 - val_loss: 4.2387\n",
      "Epoch 118/500\n",
      "43116/43116 [==============================] - 2s 49us/step - loss: 4.2107 - val_loss: 4.2376\n",
      "Epoch 119/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2257 - val_loss: 4.2395\n",
      "Epoch 120/500\n",
      "43116/43116 [==============================] - 2s 46us/step - loss: 4.2247 - val_loss: 4.2405\n",
      "Epoch 121/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2310 - val_loss: 4.2433\n",
      "Epoch 122/500\n",
      "43116/43116 [==============================] - 2s 48us/step - loss: 4.2261 - val_loss: 4.2412\n",
      "Epoch 123/500\n",
      "43116/43116 [==============================] - 2s 48us/step - loss: 4.2275 - val_loss: 4.2403\n",
      "Epoch 124/500\n",
      "43116/43116 [==============================] - 2s 44us/step - loss: 4.2191 - val_loss: 4.2404\n",
      "Epoch 125/500\n",
      "43116/43116 [==============================] - 2s 43us/step - loss: 4.2166 - val_loss: 4.2378\n",
      "Epoch 126/500\n",
      "43116/43116 [==============================] - 2s 44us/step - loss: 4.2161 - val_loss: 4.2380\n",
      "Epoch 127/500\n",
      "43116/43116 [==============================] - 2s 46us/step - loss: 4.2245 - val_loss: 4.2424\n",
      "Epoch 128/500\n",
      "43116/43116 [==============================] - 2s 45us/step - loss: 4.2255 - val_loss: 4.2384\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                    epochs=500, shuffle=True, callbacks=[es], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(scaler, open(\"scaler.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(y_test[\"total_points\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'Actual': y_true.flatten(), 'Predicted': y_pred.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInRange(actual, predicted, lower_bound=0, upper_bound=1):\n",
    "    return ((actual - predicted) >= lower_bound) and ((actual - predicted) <= upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[\"in_range\"] = pred_df.apply(lambda row: getInRange(row[\"Actual\"], row[\"Predicted\"], 0, 1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In range: 0.09\n"
     ]
    }
   ],
   "source": [
    "print(\"In range: {0:.2f}\".format(pred_df[pred_df[\"in_range\"] == True].shape[0]/pred_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>in_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.556983</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.663203</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428959</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420198</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428612</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524193</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.427868</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.606669</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416678</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.632698</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.751960</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428779</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.447375</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.538078</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.581203</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.417709</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464906</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.432079</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428322</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.558001</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.455607</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.548331</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.562493</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.503582</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.417902</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual  Predicted  in_range\n",
       "0      0.0   2.556983     False\n",
       "1      2.0   2.663203     False\n",
       "2      0.0   0.428959     False\n",
       "3      0.0   0.420198     False\n",
       "4      0.0   0.428612     False\n",
       "5      0.0   0.524193     False\n",
       "6      0.0   0.427868     False\n",
       "7      7.0   2.606669     False\n",
       "8      0.0   0.416678     False\n",
       "9      2.0   2.632698     False\n",
       "10     2.0   2.751960     False\n",
       "11     0.0   0.428779     False\n",
       "12     3.0   0.447375     False\n",
       "13     1.0   2.538078     False\n",
       "14     6.0   2.581203     False\n",
       "15     0.0   0.417709     False\n",
       "16     0.0   0.464906     False\n",
       "17     0.0   0.432079     False\n",
       "18     0.0   0.428322     False\n",
       "19     2.0   2.558001     False\n",
       "20     2.0   1.455607      True\n",
       "21     1.0   2.548331     False\n",
       "22     0.0   2.562493     False\n",
       "23     0.0   0.503582     False\n",
       "24     2.0   0.417902     False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pred_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df.plot(kind='bar',figsize=(10,8))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.2242489722651484\n",
      "R2 score: 0.23493160265723356\n",
      "Mean Squared Error: 3.8098983725057507\n",
      "Root Mean Squared Error: 1.9518960967494532\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('R2 score:', metrics.r2_score(y_test, y_pred))\n",
    "\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '{}-model.h5'.format(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_dir = os.path.join(os.getcwd(), \"..\", \"model\", season, str(gw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(gw_dir):\n",
    "    os.makedirs(gw_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(gw_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
